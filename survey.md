# Cross-Modal Self-Attention Network for Referring Image Segmentation

## 1　Introduction
**[何を目指すべきか]**
・具体的なオブジェクトカテゴリだけでなく（外見の属性・行動・相対的な関係）などの表現を解釈する。
→　クラス制約のない言語表現をどのように扱うか。
・Attentionを用いて一つの単語が持つ様々な参照表現を見出す。
・クロスモーダルなself attentionによって効率的に視覚と言語間の表現による長期的な依存性を持った特徴を学習できる。

**[従来の問題点]**
・画像と言語を別々に表現して最後に結合するので、単語の細かい表現を無視することがある。
→　単語には複数の表現がある

## 2 Related work
**[セマンティックセグメンテーション]**
・FCNはCNNの畳込み層を全結合層に置き換え、end to endの学習を可能にした。
・ダウンサンプリングや意味的文脈の拡張し、参照領域を広げてマルチスケールのプーリングを行うためにDeepLabではDilated convolutionを採用している。
・ピラミッド構造はより高度の特徴を得るために低いレベルの特徴を高いレベルへ送ります